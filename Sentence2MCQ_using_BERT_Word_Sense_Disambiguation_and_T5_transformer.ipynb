{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentence2MCQ using BERT Word Sense Disambiguation and T5 transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0c2a650e0704f47b438ee468489e697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac5a77c838ac4ffb840d85c864f3eb78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc48ee9e9f40489bb80a0746435c62d1",
              "IPY_MODEL_4985346b5c214df18c3c0b92248b906f"
            ]
          }
        },
        "ac5a77c838ac4ffb840d85c864f3eb78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc48ee9e9f40489bb80a0746435c62d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25e77ead92e94afb8b1b9d1641e18478",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6538343a7234fd3ac2481f1c6915d33"
          }
        },
        "4985346b5c214df18c3c0b92248b906f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f21dd2a65f4648e0b2b62348cb219eb2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.21k/1.21k [00:14&lt;00:00, 81.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cfaa0a20fcd476eadcb4bd1ec9bbb2a"
          }
        },
        "25e77ead92e94afb8b1b9d1641e18478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6538343a7234fd3ac2481f1c6915d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f21dd2a65f4648e0b2b62348cb219eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cfaa0a20fcd476eadcb4bd1ec9bbb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0399e0fbc5646deb5dbae5f916face0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e06edfb9642745eebc3b961d3360b6a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_116de85f0bb44faaaf6e5abd3a978ea1",
              "IPY_MODEL_70f4669b487644cfa9052b6073b31af3"
            ]
          }
        },
        "e06edfb9642745eebc3b961d3360b6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "116de85f0bb44faaaf6e5abd3a978ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8de207a43d7e4bcd88506fba7b940390",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891695056,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891695056,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51f74a52dff941ea8851c43b1865ebf5"
          }
        },
        "70f4669b487644cfa9052b6073b31af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01e219fa90d24fbbb65af32f48c1e00f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:12&lt;00:00, 71.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a15cc656e3864078884db868de9bc938"
          }
        },
        "8de207a43d7e4bcd88506fba7b940390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51f74a52dff941ea8851c43b1865ebf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01e219fa90d24fbbb65af32f48c1e00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a15cc656e3864078884db868de9bc938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebb00bca14c34df0a7c9c7edf99a0ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18236854441f4b4bb62a1d002a2f7512",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce895a94ba6646b498bc3b868c547c73",
              "IPY_MODEL_97d00c09b22548409c71fba760bc8c72"
            ]
          }
        },
        "18236854441f4b4bb62a1d002a2f7512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce895a94ba6646b498bc3b868c547c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e796777c2af6419ea61f2db88d0ee90e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4fb069529ce408b9af67c0be916000c"
          }
        },
        "97d00c09b22548409c71fba760bc8c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36a51affe4fe434ea172576eb2fd2bbf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:07&lt;00:00, 99.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e982cbfaaeb84dcfacee2066930c15ab"
          }
        },
        "e796777c2af6419ea61f2db88d0ee90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4fb069529ce408b9af67c0be916000c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36a51affe4fe434ea172576eb2fd2bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e982cbfaaeb84dcfacee2066930c15ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7DFNSwyfFuu"
      },
      "source": [
        "BERT Word Sense Disambiguation is adapted from the awesome repo here. [BERT WSD](https://github.com/BPYap/BERT-WSD) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvo1s6FWjn6s"
      },
      "source": [
        "## Installation and mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4q45GmGwVbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dd492b-1bbd-4ca7-cb7e-1eff211027e7"
      },
      "source": [
        "!pip install --quiet transformers==2.9.0\r\n",
        "!pip install --quiet nltk==3.4.5\r\n",
        "!pip install --quiet gradio==1.4.2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 645kB 20.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 59.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 59.5MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 18.4MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 17.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 52.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 962kB 57.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 56.9MB/s \n",
            "\u001b[?25h  Building wheel for Flask-BasicAuth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy6IZ7sjTf4g",
        "outputId": "a8836e26-971c-40c6-f9ec-9fcbc1703cbc"
      },
      "source": [
        "# connect your personal google drive to store the trained model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neRbWQhO4GnG"
      },
      "source": [
        "## Download pretrained BERT WSD Model - Run only once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rELsk4JIMhJ3"
      },
      "source": [
        "Download pre-trained BERT WSD from [here](https://entuedu-my.sharepoint.com/:f:/g/personal/boonpeng001_e_ntu_edu_sg/EiWzblOyyOBDtuO3klUbXoAB3THFzke-2MLWguIXrDopWg?e=08umXD)\r\n",
        "\r\n",
        "Click the download button at the top left of the link to download a file named \"bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\r\n",
        "\r\n",
        "Place the zip file in your Google drive home folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNz0zFZzrXqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84c19a4-e79f-4012-b771-b781ee93447a"
      },
      "source": [
        "import os\r\n",
        "import zipfile\r\n",
        "\r\n",
        "bert_wsd_pytorch = \"/content/drive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\r\n",
        "extract_directory = \"/content/drive/My Drive\"\r\n",
        "\r\n",
        "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\r\n",
        "\r\n",
        "#  If unzipped folder exists don't unzip again.\r\n",
        "if not os.path.isdir(extracted_folder):\r\n",
        "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\r\n",
        "      zip_ref.extractall(extract_directory)\r\n",
        "else:\r\n",
        "  print (extracted_folder,\" is extracted already\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6  is extracted already\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GtYSH2ewtO4"
      },
      "source": [
        "# Run model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnmszaP9zSpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62808823-744c-463e-a729-ab170ded9db7"
      },
      "source": [
        "import torch\r\n",
        "import math\r\n",
        "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\r\n",
        "\r\n",
        "class BertWSD(BertPreTrainedModel):\r\n",
        "    def __init__(self, config):\r\n",
        "        super().__init__(config)\r\n",
        "\r\n",
        "        self.bert = BertModel(config)\r\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\r\n",
        "\r\n",
        "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\r\n",
        "\r\n",
        "        self.init_weights()\r\n",
        "\r\n",
        "\r\n",
        "# def _forward(args, model, batch):\r\n",
        "#     batch = tuple(t.to(args.device) for t in batch)\r\n",
        "#     outputs = model.bert(input_ids=batch[0], attention_mask=batch[1], token_type_ids=batch[2])\r\n",
        "\r\n",
        "#     return model.dropout(outputs[1])\r\n",
        "    \r\n",
        "\r\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model_dir = \"/content/drive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\r\n",
        "\r\n",
        "\r\n",
        "model = BertWSD.from_pretrained(model_dir)\r\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\r\n",
        "# add new special token\r\n",
        "if '[TGT]' not in tokenizer.additional_special_tokens:\r\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\r\n",
        "    assert '[TGT]' in tokenizer.additional_special_tokens\r\n",
        "    model.resize_token_embeddings(len(tokenizer))\r\n",
        "    \r\n",
        "model.to(DEVICE)\r\n",
        "model.eval()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWSD(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0bWxo4vFUfH",
        "outputId": "dc038cfc-e4c9-4359-94d7-e29e9586e021"
      },
      "source": [
        "import csv\r\n",
        "import os\r\n",
        "from collections import namedtuple\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('wordnet')\r\n",
        "from nltk.corpus import wordnet as wn\r\n",
        "\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\r\n",
        "BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\r\n",
        "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\r\n",
        "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\r\n",
        "                                  cls_token_segment_id=1, pad_token_segment_id=0,\r\n",
        "                                  mask_padding_with_zero=True, disable_progress_bar=False):\r\n",
        "    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\r\n",
        "        always the feature created from context-gloss pair while the rest of the elements are features created from\r\n",
        "        context-example pairs (if available)\r\n",
        "        `cls_token_at_end` define the location of the CLS token:\r\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\r\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\r\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\r\n",
        "    \"\"\"\r\n",
        "    features = []\r\n",
        "    for record in tqdm(records, disable=disable_progress_bar):\r\n",
        "        tokens_a = tokenizer.tokenize(record.sentence)\r\n",
        "\r\n",
        "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\r\n",
        "\r\n",
        "        pairs = []\r\n",
        "        for seq, label in sequences:\r\n",
        "            tokens_b = tokenizer.tokenize(seq)\r\n",
        "\r\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\r\n",
        "            # length is less than the specified length.\r\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\r\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\r\n",
        "\r\n",
        "            # The convention in BERT is:\r\n",
        "            # (a) For sequence pairs:\r\n",
        "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\r\n",
        "            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\r\n",
        "            #\r\n",
        "            # Where \"type_ids\" are used to indicate whether this is the first\r\n",
        "            # sequence or the second sequence. The embedding vectors for `type=0` and\r\n",
        "            # `type=1` were learned during pre-training and are added to the wordpiece\r\n",
        "            # embedding vector (and position vector). This is not *strictly* necessary\r\n",
        "            # since the [SEP] token unambiguously separates the sequences, but it makes\r\n",
        "            # it easier for the model to learn the concept of sequences.\r\n",
        "            #\r\n",
        "            # For classification tasks, the first vector (corresponding to [CLS]) is\r\n",
        "            # used as as the \"sentence vector\". Note that this only makes sense because\r\n",
        "            # the entire model is fine-tuned.\r\n",
        "            tokens = tokens_a + [sep_token]\r\n",
        "            segment_ids = [sequence_a_segment_id] * len(tokens)\r\n",
        "\r\n",
        "            tokens += tokens_b + [sep_token]\r\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\r\n",
        "\r\n",
        "            if cls_token_at_end:\r\n",
        "                tokens = tokens + [cls_token]\r\n",
        "                segment_ids = segment_ids + [cls_token_segment_id]\r\n",
        "            else:\r\n",
        "                tokens = [cls_token] + tokens\r\n",
        "                segment_ids = [cls_token_segment_id] + segment_ids\r\n",
        "\r\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\r\n",
        "\r\n",
        "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\r\n",
        "            # tokens are attended to.\r\n",
        "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\r\n",
        "\r\n",
        "            # Zero-pad up to the sequence length.\r\n",
        "            padding_length = max_seq_length - len(input_ids)\r\n",
        "            if pad_on_left:\r\n",
        "                input_ids = ([pad_token] * padding_length) + input_ids\r\n",
        "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\r\n",
        "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\r\n",
        "            else:\r\n",
        "                input_ids = input_ids + ([pad_token] * padding_length)\r\n",
        "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\r\n",
        "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\r\n",
        "\r\n",
        "            assert len(input_ids) == max_seq_length\r\n",
        "            assert len(input_mask) == max_seq_length\r\n",
        "            assert len(segment_ids) == max_seq_length\r\n",
        "\r\n",
        "            pairs.append(\r\n",
        "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\r\n",
        "            )\r\n",
        "\r\n",
        "        features.append(pairs)\r\n",
        "\r\n",
        "    return features\r\n",
        "\r\n",
        "\r\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\r\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\r\n",
        "\r\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\r\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\r\n",
        "    # of tokens from each, since if one sequence is very short then each token\r\n",
        "    # that's truncated likely contains more information than a longer sequence.\r\n",
        "    while True:\r\n",
        "        total_length = len(tokens_a) + len(tokens_b)\r\n",
        "        if total_length <= max_length:\r\n",
        "            break\r\n",
        "        if len(tokens_a) > len(tokens_b):\r\n",
        "            tokens_a.pop()\r\n",
        "        else:\r\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJSpZRuOF-52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "f0c2a650e0704f47b438ee468489e697",
            "ac5a77c838ac4ffb840d85c864f3eb78",
            "cc48ee9e9f40489bb80a0746435c62d1",
            "4985346b5c214df18c3c0b92248b906f",
            "25e77ead92e94afb8b1b9d1641e18478",
            "e6538343a7234fd3ac2481f1c6915d33",
            "f21dd2a65f4648e0b2b62348cb219eb2",
            "7cfaa0a20fcd476eadcb4bd1ec9bbb2a",
            "b0399e0fbc5646deb5dbae5f916face0",
            "e06edfb9642745eebc3b961d3360b6a3",
            "116de85f0bb44faaaf6e5abd3a978ea1",
            "70f4669b487644cfa9052b6073b31af3",
            "8de207a43d7e4bcd88506fba7b940390",
            "51f74a52dff941ea8851c43b1865ebf5",
            "01e219fa90d24fbbb65af32f48c1e00f",
            "a15cc656e3864078884db868de9bc938",
            "ebb00bca14c34df0a7c9c7edf99a0ab2",
            "18236854441f4b4bb62a1d002a2f7512",
            "ce895a94ba6646b498bc3b868c547c73",
            "97d00c09b22548409c71fba760bc8c72",
            "e796777c2af6419ea61f2db88d0ee90e",
            "f4fb069529ce408b9af67c0be916000c",
            "36a51affe4fe434ea172576eb2fd2bbf",
            "e982cbfaaeb84dcfacee2066930c15ab"
          ]
        },
        "outputId": "ee6e0b59-3b0e-4c04-b572-382225aabc30"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "import torch\r\n",
        "from tabulate import tabulate\r\n",
        "from torch.nn.functional import softmax\r\n",
        "from tqdm import tqdm\r\n",
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "import time\r\n",
        "\r\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\r\n",
        "\r\n",
        "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\r\n",
        "question_tokenizer = T5Tokenizer.from_pretrained('t5-base')\r\n",
        "\r\n",
        "MAX_SEQ_LENGTH = 128\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_sense(sent):\r\n",
        "\r\n",
        "  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\r\n",
        "  if re_result is None:\r\n",
        "      print(\"\\nIncorrect input format. Please try again.\")\r\n",
        "\r\n",
        "  ambiguous_word = re_result.group(1).strip()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  results = dict()\r\n",
        "\r\n",
        "  wn_pos = wn.NOUN\r\n",
        "  for i, synset in enumerate(set(wn.synsets(ambiguous_word, pos=wn_pos))):\r\n",
        "      results[synset] =  synset.definition()\r\n",
        "\r\n",
        "  if len(results) ==0:\r\n",
        "    return (None,None,ambiguous_word)\r\n",
        "\r\n",
        "  # print (results)\r\n",
        "  sense_keys=[]\r\n",
        "  definitions=[]\r\n",
        "  for sense_key, definition in results.items():\r\n",
        "      sense_keys.append(sense_key)\r\n",
        "      definitions.append(definition)\r\n",
        "\r\n",
        "\r\n",
        "  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\r\n",
        "\r\n",
        "  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\r\n",
        "                                            cls_token=tokenizer.cls_token,\r\n",
        "                                            sep_token=tokenizer.sep_token,\r\n",
        "                                            cls_token_segment_id=1,\r\n",
        "                                            pad_token_segment_id=0,\r\n",
        "                                            disable_progress_bar=True)[0]\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\r\n",
        "      for i, bert_input in tqdm(list(enumerate(features)), desc=\"Progress\"):\r\n",
        "          logits[i] = model.ranking_linear(\r\n",
        "              model.bert(\r\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\r\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\r\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\r\n",
        "              )[1]\r\n",
        "          )\r\n",
        "      scores = softmax(logits, dim=0)\r\n",
        "\r\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\r\n",
        "\r\n",
        "\r\n",
        "  # print (preds)\r\n",
        "  sense = preds[0][0]\r\n",
        "  meaning = preds[0][1]\r\n",
        "  return (sense,meaning,ambiguous_word)\r\n",
        "\r\n",
        "\r\n",
        "# Distractors from Wordnet\r\n",
        "def get_distractors_wordnet(syn,word):\r\n",
        "    distractors=[]\r\n",
        "    word= word.lower()\r\n",
        "    orig_word = word\r\n",
        "    if len(word.split())>0:\r\n",
        "        word = word.replace(\" \",\"_\")\r\n",
        "    hypernym = syn.hypernyms()\r\n",
        "    if len(hypernym) == 0: \r\n",
        "        return distractors\r\n",
        "    for item in hypernym[0].hyponyms():\r\n",
        "        name = item.lemmas()[0].name()\r\n",
        "        #print (\"name \",name, \" word\",orig_word)\r\n",
        "        if name == orig_word:\r\n",
        "            continue\r\n",
        "        name = name.replace(\"_\",\" \")\r\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\r\n",
        "        if name is not None and name not in distractors:\r\n",
        "            distractors.append(name)\r\n",
        "    return distractors\r\n",
        "\r\n",
        "\r\n",
        "def get_question(sentence,answer):\r\n",
        "  text = \"context: {} answer: {} </s>\".format(sentence,answer)\r\n",
        "  max_len = 256\r\n",
        "  encoding = question_tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=True, return_tensors=\"pt\")\r\n",
        "\r\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\r\n",
        "\r\n",
        "  outs = question_model.generate(input_ids=input_ids,\r\n",
        "                                  attention_mask=attention_mask,\r\n",
        "                                  early_stopping=True,\r\n",
        "                                  num_beams=5,\r\n",
        "                                  num_return_sequences=1,\r\n",
        "                                  no_repeat_ngram_size=2,\r\n",
        "                                  max_length=200)\r\n",
        "\r\n",
        "\r\n",
        "  dec = [question_tokenizer.decode(ids) for ids in outs]\r\n",
        "\r\n",
        "\r\n",
        "  Question = dec[0].replace(\"question:\",\"\")\r\n",
        "  Question= Question.strip()\r\n",
        "  return Question\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0c2a650e0704f47b438ee468489e697",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1208.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0399e0fbc5646deb5dbae5f916face0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891695056.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebb00bca14c34df0a7c9c7edf99a0ab2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKbPKBjr-KTp",
        "outputId": "8cce5193-bf4d-47f1-b195-42e805c1e82a"
      },
      "source": [
        "def getMCQs(sent):\r\n",
        "  sentence_for_bert = sent.replace(\"**\",\" [TGT] \")\r\n",
        "  sentence_for_bert = \" \".join(sentence_for_bert.split())\r\n",
        "  # try:\r\n",
        "  sense,meaning,answer = get_sense(sentence_for_bert)\r\n",
        "  if sense is not None:\r\n",
        "    distractors = get_distractors_wordnet(sense,answer)\r\n",
        "  else: \r\n",
        "    distractors = [\"Word not found in Wordnet. So unable to extract distractors.\"]\r\n",
        "  sentence_for_T5 = sent.replace(\"**\",\" \")\r\n",
        "  sentence_for_T5 = \" \".join(sentence_for_T5.split()) \r\n",
        "  ques = get_question(sentence_for_T5,answer)\r\n",
        "  return ques,answer,distractors,meaning\r\n",
        "\r\n",
        "\r\n",
        "sentence = \"Mark's favourite game is **Cricket**.\"\r\n",
        "\r\n",
        "\r\n",
        "question,answer,distractors,meaning = getMCQs(sentence)\r\n",
        "print (question)\r\n",
        "print (answer)\r\n",
        "print (distractors)\r\n",
        "print (meaning)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress: 100%|██████████| 2/2 [00:00<00:00, 14.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "What is Mark's favorite game?\n",
            "Cricket\n",
            "['Ball Game', 'Field Hockey', 'Football', 'Hurling', 'Lacrosse', 'Polo', 'Pushball', 'Ultimate Frisbee']\n",
            "a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "SpYhWgr7Z79p",
        "outputId": "4bfde668-bdef-4e48-b409-e1357b02aae9"
      },
      "source": [
        "# sentence = John went to river **bank** to cry\r\n",
        "# sentence = John went to deposit money in the **bank**\r\n",
        "\r\n",
        "# sentence = John bought a **mouse** for his computer.\r\n",
        "# sentence = John saw a **mouse** under his bed.\r\n",
        "\r\n",
        "# sentence = Mark is annoyed by a **cricket** in his room.\r\n",
        "# sentence = Mark's favourite game is **Cricket**.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import gradio as gr\r\n",
        "\r\n",
        "def greet(sen):\r\n",
        "  question,answer,distractors,meaning = getMCQs(sen)\r\n",
        "  distractors_string =  ', '.join(distractors)\r\n",
        "  return question,answer.capitalize(),distractors_string,meaning\r\n",
        "\r\n",
        "textbox1 = gr.outputs.Textbox( type=\"auto\", label=\"Question\")\r\n",
        "textbox2 = gr.outputs.Textbox(type=\"auto\", label=\"Correct Answer\")\r\n",
        "textbox3 = gr.outputs.Textbox( type=\"auto\", label=\"Distractors (wrong choices)\")\r\n",
        "textbox4 = gr.outputs.Textbox( type=\"auto\", label=\"Sense extracted from Wordnet\")\r\n",
        "\r\n",
        "iface = gr.Interface(\r\n",
        "  fn=greet, \r\n",
        "  inputs=gr.inputs.Textbox(lines=2,label=\"Input Sentence\", default=\"Mark's favorite game is **Cricket**.\"), \r\n",
        "  outputs=[textbox1,textbox2,textbox3,textbox4])\r\n",
        "iface.launch()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMPORTANT: You are using gradio version 1.4.2, however version 1.5.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "This share link will expire in 24 hours. If you need a permanent link, email support@gradio.app\n",
            "Running on External URL: https://33234.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://33234.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f947490a320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://33234.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}